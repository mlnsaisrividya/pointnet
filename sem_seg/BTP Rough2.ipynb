{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a403cc91",
   "metadata": {},
   "source": [
    "Visualisation of given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36196391",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-8b1644b599b2>:4: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  f = h5py.File(h5_filename)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "def load_h5(h5_filename):\n",
    "    f = h5py.File(h5_filename)\n",
    "    data = f['data'][:]\n",
    "    label = f['label'][:]\n",
    "    return (data, label)\n",
    "h5_filename = 'indoor3d_sem_seg_hdf5_data/ply_data_all_1.h5'\n",
    "data_batch, label_batch = load_h5(h5_filename)\n",
    "#dps = data_batch[0:80,:,0:6] # area1 conference1\n",
    "#lbs = label_batch[0:80,:]\n",
    "dps = data_batch[:,:,0:6] # area1 conference1\n",
    "lbs = label_batch[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d42b009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4096, 3)\n",
      "(1000, 4096, 3)\n"
     ]
    }
   ],
   "source": [
    "pts = dps[:,:,0:3]\n",
    "cls = dps[:,:,3:6]\n",
    "print(pts.shape)\n",
    "print(cls.shape)\n",
    "type(pts)\n",
    "#all points in one place for visualisation purpose \n",
    "new_pts = pts.reshape((pts.shape[0]*pts.shape[1]),pts.shape[2])\n",
    "new_cls = cls.reshape((cls.shape[0]*cls.shape[1]),cls.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "516cb534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(new_pts)\n",
    "pcd.colors = o3d.utility.Vector3dVector(new_cls)\n",
    "#o3d.io.write_point_cloud(\"./data.ply\", pcd)\n",
    "o3d.visualization.draw_geometries([pcd])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07538ba7",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2a36fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import MaxPooling2D, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import h5py\n",
    "def load_h5(h5_filename):\n",
    "    f = h5py.File(h5_filename)\n",
    "    data = f['data'][:]\n",
    "    label = f['label'][:]\n",
    "    return (data, label)\n",
    "\n",
    "# SOME_FILES = [line.rstrip() for line in open('indoor3d_sem_seg_hdf5_data/someFiles.txt')]#provider.getDataFiles('indoor3d_sem_seg_hdf5_data/all_files.txt')\n",
    "# # Load ALL data\n",
    "# data_batch_list = []\n",
    "# label_batch_list = []\n",
    "# for h5_filename in SOME_FILES:\n",
    "#     data_batch, label_batch = load_h5(h5_filename)\n",
    "#     data_batch_list.append(data_batch)\n",
    "#     label_batch_list.append(label_batch)\n",
    "# data_batches = np.concatenate(data_batch_list, 0)\n",
    "# label_batches = np.concatenate(label_batch_list, 0)\n",
    "\n",
    "data_batch, label_batch = load_h5('indoor3d_sem_seg_hdf5_data/ply_data_all_5.h5')\n",
    "data_batches = data_batch[0:100,:,:]\n",
    "label_batches = label_batch[0:100,:]\n",
    "print(data_batches.shape)\n",
    "print(label_batches.shape)\n",
    "#cat_labels = tf.keras.utils.to_categorical(label_batches, num_classes = 13, dtype = \"uint8\")\n",
    "X_train, X_test, Y_train, Y_test = train_test_split( data_batches, label_batches , test_size=0.2, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "input_image = keras.Input(shape = (4096,9,1))                                                            #B*N*9*1\n",
    "num_point = 4096\n",
    "x = Conv2D(64, [1,9], padding='VALID', strides = [1,1], activation = 'relu', name ='conv1')(input_image) #B*N*1*64\n",
    "print(x.shape)\n",
    "x = Conv2D(64, [1,1], padding='VALID', strides = [1,1], activation = 'relu', name ='conv2')(x)           #B*N*1*64\n",
    "x = Conv2D(64, [1,1], padding='VALID', strides = [1,1], activation = 'relu', name ='conv3')(x)           #B*N*1*64\n",
    "x = Conv2D(128, [1,1], padding='VALID', strides = [1,1],activation = 'relu', name ='conv4')(x)           #B*N*1*128\n",
    "x= Conv2D(1024, [1,1], padding='VALID', strides = [1,1], activation = 'relu',name ='conv5')(x)           #B*N*1*1024\n",
    "                                                                    #Now x is partial feature vector of each point\n",
    "    # max pooling as a symmetric function is a key point to solve the cloud of disorder.\n",
    "print(x.shape)\n",
    "pc_feat1 = MaxPooling2D([num_point,1],strides=(2, 2), padding='VALID', name ='maxpool1')(x)   #maxpooling for each channel \n",
    "print(pc_feat1.shape)\n",
    "pc_feat1 = Flatten()(pc_feat1)\n",
    "print(pc_feat1.shape)\n",
    "#model.add(Flatten())\n",
    "pc_feat1 = Dense(256, activation = 'relu', name='fc1')(pc_feat1)        #global feature vectors through fully connected layers                                                      \n",
    "pc_feat1 = Dense(128 , activation = 'relu', name='fc2')(pc_feat1)\n",
    "print(pc_feat1.shape)\n",
    "# CONCAT\n",
    "a = tf.keras.layers.Reshape((1, 1, -1))(pc_feat1)                   #B*1*1*128\n",
    "print(a.shape)\n",
    "\n",
    "pc_feat1_expand = tf.tile(a, [1, num_point, 1, 1])                  #B*N*1*128\n",
    "print(pc_feat1_expand.shape)\n",
    "points_feat1_concat = tf.concat(axis=3, values=[x, pc_feat1_expand])#B*N*1*1152    (1024+128)axis = 3 implies along 4th column\n",
    "print(points_feat1_concat.shape)\n",
    "# CONV\n",
    "\n",
    "y = Conv2D(512, [1, 1], padding='VALID', strides=[1, 1], activation = 'relu', name='conv6')(points_feat1_concat)\n",
    "y = Conv2D(256, [1, 1], padding='VALID', strides=[1, 1], activation = 'relu', name='conv7')(y)\n",
    "# tf.keras.layers.Dropout(rate, noise_shape=None, seed=None, **kwargs)\n",
    "\n",
    "y = Dropout(rate=0.3)(y)                                                #rate = Fraction of the input units to drop.\n",
    "y = Conv2D(13, [1, 1], padding='VALID', strides=[1, 1], activation = 'softmax', name='conv8')(y)#B*N*1*13\n",
    "net = tf.squeeze(y, [2])                                                #B*N*13\n",
    "\n",
    "# return net\n",
    "model = keras.Model(inputs=input_image, outputs=net)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=[\"sparse_categorical_accuracy\"])\n",
    "# loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
    "\n",
    "history = model.fit(X_train, Y_train, batch_size=20, epochs=10, verbose=1)     #verbose=0 will show you nothing (silent)\n",
    "model.evaluate(X_test, Y_test, verbose=2)    #verbose=1 will show you an animated progress bar & verbose=2 will just mention the number of epoch\n",
    "predictions = model.predict(X_test)\n",
    "#pred = keras.utils.np_utils.probas_to_classes(model.predict(X_test))\n",
    "pred = np.argmax(predictions,axis=2)\n",
    "# plot loss during training\n",
    "#pred = tf.nn.softmax(predictions)\n",
    "# show the inputs and predicted outputs\n",
    "# for i in range(10):\n",
    "# \tprint(\"actual=%s, Predicted=%s\" % (Y_test[i], pred[i]))\n",
    "print(pred.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "print(\"Y_test[1] shape\")\n",
    "print(Y_test[1].shape)\n",
    "print(pred[1].shape)\n",
    "print(\"actual=%s, Predicted=%s\" % (Y_test[1,:25], pred[1,:25]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69e77fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
